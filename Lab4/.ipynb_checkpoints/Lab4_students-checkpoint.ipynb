{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import\n",
    "## Question 0 - Get common wikidata occupations\n",
    "\n",
    "> Write a sparql query that retrieves the top 100 occupations on wikidata (wikidata property P106).\n",
    "\n",
    "You may use the interface https://query.wikidata.org/ to try different queries. Here are some example sparql queries: https://www.wikidata.org/wiki/Wikidata:SPARQL_query_service/queries/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT ?o [TO COMPLETE HERE...]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following assertion should pass if your answer is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3cbfe4c09707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m myOccupations = [val['o']['value'].replace('http://www.wikidata.org/entity/', '') \n\u001b[0;32m---> 13\u001b[0;31m                  for val in evalSparql(query)]\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moccupations\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyOccupations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-3cbfe4c09707>\u001b[0m in \u001b[0;36mevalSparql\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m'content-type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'application/sparql-query'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;34m'accept'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'application/json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;34m'user-agent'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'User:Tpt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     }).json()['results']['bindings']\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m                     \u001b[0;31m# used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "occupations = ['Q82955', 'Q937857', 'Q36180', 'Q33999', 'Q1650915', 'Q1028181', 'Q1930187', 'Q177220', 'Q1622272', 'Q49757', 'Q36834', 'Q40348', 'Q47064', 'Q639669', 'Q10800557', 'Q201788', 'Q2526255', 'Q43845', 'Q28389', 'Q42973', 'Q10871364', 'Q39631', 'Q193391', 'Q482980', 'Q483501', 'Q11513337', 'Q3665646', 'Q12299841', 'Q19204627', 'Q16533', 'Q81096', 'Q11774891', 'Q188094', 'Q1281618', 'Q333634', 'Q189290', 'Q250867', 'Q33231', 'Q2259451', 'Q42603', 'Q628099', 'Q37226', 'Q2309784', 'Q901', 'Q2066131', 'Q6625963', 'Q10798782', 'Q2374149', 'Q170790', 'Q4610556', 'Q185351', 'Q486748', 'Q3055126', 'Q753110', 'Q4964182', 'Q169470', 'Q158852', 'Q1234713', 'Q14089670', 'Q10873124', 'Q3282637', 'Q593644', 'Q947873', 'Q13414980', 'Q131524', 'Q11338576', 'Q15117302', 'Q488205', 'Q14467526', 'Q183945', 'Q10843402', 'Q13382576', 'Q13141064', 'Q214917', 'Q855091', 'Q644687', 'Q19595175', 'Q121594', 'Q2865819', 'Q16010345', 'Q1231865', 'Q2405480', 'Q350979', 'Q3400985', 'Q13365117', 'Q10833314', 'Q3621491', 'Q15981151', 'Q212980', 'Q16145150', 'Q1792450', 'Q15296811', 'Q15627169', 'Q2306091', 'Q4263842', 'Q806798', 'Q5716684', 'Q2516866', 'Q3387717', 'Q131512']\n",
    "\n",
    "def evalSparql(query):\n",
    "    return requests.post('https://query.wikidata.org/sparql', data=query, headers={\n",
    "        'content-type': 'application/sparql-query',\n",
    "        'accept': 'application/json',\n",
    "        'user-agent': 'User:Tpt'\n",
    "    }).json()['results']['bindings']\n",
    "\n",
    "myOccupations = [val['o']['value'].replace('http://www.wikidata.org/entity/', '') \n",
    "                 for val in evalSparql(query)]\n",
    "assert(frozenset(occupations) == frozenset(myOccupations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occupations labels\n",
    "\n",
    "We load the labels of the occupations from Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Q42973': 'architect', 'Q188094': 'economist', 'Q201788': 'historian', 'Q14467526': 'linguist', 'Q1281618': 'sculptor', 'Q177220': 'singer', 'Q1650915': 'researcher', 'Q628099': 'association football manager', 'Q753110': 'songwriter', 'Q40348': 'lawyer', 'Q12299841': 'cricketer', 'Q1231865': 'pedagogue', 'Q488205': 'singer-songwriter', 'Q158852': 'conductor', 'Q121594': 'professor', 'Q1792450': 'art historian', 'Q183945': 'record producer', 'Q482980': 'author', 'Q1930187': 'journalist', 'Q19595175': 'amateur wrestler', 'Q16533': 'judge', 'Q855091': 'guitarist', 'Q483501': 'artist', 'Q47064': 'military personnel', 'Q131524': 'entrepreneur', 'Q214917': 'playwright', 'Q37226': 'teacher', 'Q28389': 'screenwriter', 'Q639669': 'musician', 'Q1028181': 'painter', 'Q644687': 'illustrator', 'Q39631': 'physician', 'Q11513337': 'athletics competitor', 'Q1234713': 'theologian', 'Q13141064': 'badminton player', 'Q13382576': 'rower', 'Q43845': 'businessperson', 'Q2374149': 'botanist', 'Q3665646': 'basketball player', 'Q2405480': 'voice actor', 'Q16010345': 'performer', 'Q3055126': 'entomologist', 'Q10800557': 'film actor', 'Q4964182': 'philosopher', 'Q33231': 'photographer', 'Q36180': 'writer', 'Q2865819': 'opera singer', 'Q6625963': 'novelist', 'Q131512': 'agriculturer', 'Q11774891': 'ice hockey player', 'Q33999': 'actor', 'Q13414980': 'Australian rules footballer', 'Q169470': 'physicist', 'Q2526255': 'film director', 'Q15296811': 'drawer', 'Q10873124': 'chess player', 'Q3621491': 'archaeologist', 'Q937857': 'association football player', 'Q4263842': 'literary critic', 'Q81096': 'engineer', 'Q806798': 'banker', 'Q5716684': 'dancer', 'Q19204627': 'American football player', 'Q14089670': 'rugby union player', 'Q49757': 'poet', 'Q15627169': 'trade unionist', 'Q3400985': 'academic', 'Q10798782': 'television actor', 'Q2259451': 'stage actor', 'Q42603': 'priest', 'Q2066131': 'athlete', 'Q189290': 'military officer', 'Q82955': 'politician', 'Q947873': 'television presenter', 'Q333634': 'translator', 'Q11338576': 'boxer', 'Q15117302': 'volleyball player', 'Q901': 'scientist', 'Q250867': 'Catholic priest', 'Q193391': 'diplomat', 'Q486748': 'pianist', 'Q10871364': 'baseball player', 'Q4610556': 'model', 'Q10843402': 'swimmer', 'Q15981151': 'jazz musician', 'Q3282637': 'film producer', 'Q185351': 'jurist', 'Q170790': 'mathematician', 'Q1622272': 'university teacher', 'Q2306091': 'sociologist', 'Q36834': 'composer', 'Q212980': 'psychologist', 'Q16145150': 'music pedagogue', 'Q2516866': 'publisher', 'Q13365117': 'handball player', 'Q2309784': 'sport cyclist', 'Q350979': 'zoologist', 'Q3387717': 'theatre director', 'Q10833314': 'tennis player', 'Q593644': 'chemist'}\n"
     ]
    }
   ],
   "source": [
    "occupations_label = {}\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT ?o ?oLabel \n",
    "WHERE { \n",
    "    VALUES ?o { %s } \n",
    "    SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "}\"\"\"% ' '.join('wd:' + o for o in occupations)\n",
    "\n",
    "for result in evalSparql(query):\n",
    "    occupations_label[result['o']['value'].replace('http://www.wikidata.org/entity/', '')] = result['oLabel']['value']\n",
    "\n",
    "print(occupations_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load *all* the labels of the occupations from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Q188094': ['economist'], 'Q201788': ['historian', 'historiographer', 'historians'], 'Q14467526': ['linguist', 'linguistic scholar'], 'Q1281618': ['sculptor'], 'Q177220': ['singer', 'vocalist'], 'Q1650915': ['researcher'], 'Q628099': ['association football manager', 'football manager', 'soccer coach', 'association football coach', 'football coach', 'soccer manager'], 'Q753110': ['songwriter', 'song writer'], 'Q40348': ['lawyer', 'attorney', 'Jurisprudente'], 'Q12299841': ['cricketer', 'cricket player'], 'Q1231865': ['pedagogue', 'educationalist'], 'Q488205': ['singer-songwriter', 'singer songwriter', 'singer/songwriter', 'singersongwriter'], 'Q158852': ['conductor', 'Conducting'], 'Q121594': ['professor', 'Prof.'], 'Q1792450': ['art historian'], 'Q183945': ['record producer', 'music producer'], 'Q482980': ['author'], 'Q1930187': ['journalist', 'journo'], 'Q19595175': ['amateur wrestler', 'wrestler'], 'Q16533': ['judge', 'magistrate', 'justice', 'judges', 'justices'], 'Q855091': ['guitarist', 'guitar player'], 'Q350979': ['zoologist', 'zooligist'], 'Q483501': ['artist'], 'Q47064': ['military personnel'], 'Q131524': ['entrepreneur'], 'Q1234713': ['theologian', 'religious scholar'], 'Q37226': ['teacher', 'professor', 'educator', 'schoolmaster', 'schoolmistress', 'school teacher'], 'Q28389': ['screenwriter', 'scenarist', 'scriptwriter', 'writer', 'film writer', 'screen writer', 'tv writer', 'script writer'], 'Q639669': ['musician'], 'Q1028181': ['painter'], 'Q644687': ['illustrator'], 'Q39631': ['physician', 'physicians'], 'Q11513337': ['athletics competitor', 'track and field athlete', 'athlete (restricted sense)'], 'Q214917': ['playwright', 'scriptwriter', 'dramatist', 'Playwright, dramatist', 'playwrite'], 'Q13141064': ['badminton player'], 'Q13382576': ['rower', 'oarsman', 'oarswoman'], 'Q43845': ['businessperson', 'business man', 'business person', 'business woman', 'businessman', 'businesswoman', 'dealer'], 'Q2374149': ['botanist', 'botany', 'plant scientist'], 'Q3665646': ['basketball player', 'professional basketball player', 'basketballer'], 'Q2405480': ['voice actor', 'voice actress', 'voice artist'], 'Q16010345': ['performer', 'performing artist', 'scenic artist'], 'Q3055126': ['entomologist'], 'Q4263842': ['literary critic', 'book critic', 'literary critique'], 'Q4964182': ['philosopher'], 'Q33231': ['photographer'], 'Q36180': ['writer', 'author'], 'Q486748': ['pianist'], 'Q6625963': ['novelist'], 'Q131512': ['agriculturer', 'farmer', 'agriculturist', 'cultivator', 'grower', 'raiser'], 'Q11774891': ['ice hockey player', 'hockey player'], 'Q33999': ['actor', 'actresses', 'actress', 'actors'], 'Q13414980': ['Australian rules footballer', 'Australian footballer', 'Australian rules football player', 'Australian-rules football player'], 'Q169470': ['physicist'], 'Q2526255': ['film director', 'director', 'movie director'], 'Q15296811': ['drawer', 'illustrator', 'draftsperson', 'draughtsperson', 'draftsman', 'drafter', 'draftswoman', 'draughtsman'], 'Q10873124': ['chess player'], 'Q3621491': ['archaeologist', 'archeologist'], 'Q937857': ['association football player', 'football player', 'footballer', 'association footballer', 'soccer player'], 'Q10800557': ['film actor', 'movie actress', 'film actress', 'movie actor'], 'Q81096': ['engineer'], 'Q806798': ['banker', 'Private Banker', 'private sector banker'], 'Q5716684': ['dancer'], 'Q19204627': ['American football player', 'football player'], 'Q14089670': ['rugby union player'], 'Q49757': ['poet', 'bard', 'poetess'], 'Q15627169': ['trade unionist', 'labor unionist', 'labour unionist'], 'Q3400985': ['academic', 'college graduates', 'university graduates'], 'Q10798782': ['television actor', 'actress', 'actor', 'TV actor', 'television actress', 'TV actress'], 'Q2259451': ['stage actor', 'stage actress', 'theater actor', 'theater actress', 'theatre actor', 'theatre actress'], 'Q42603': ['priest', 'reverend', 'priestess'], 'Q2066131': ['athlete', 'sportsperson', 'sportsman', 'sportswoman'], 'Q189290': ['military officer', 'officer', 'army officer'], 'Q3282637': ['film producer', 'producer', 'movie producer'], 'Q947873': ['television presenter', 'TV host', 'host', 'hostess', 'TV presenter', 'television personality', 'TV personality', 'television host'], 'Q333634': ['translator'], 'Q11338576': ['boxer', 'pugilist'], 'Q15117302': ['volleyball player', 'volleyballer'], 'Q901': ['scientist', 'natural philosopher'], 'Q250867': ['Catholic priest', 'Roman Catholic priest', 'Catholic presbyter', 'Roman Catholic presbyter'], 'Q193391': ['diplomat'], 'Q2865819': ['opera singer'], 'Q10871364': ['baseball player'], 'Q4610556': ['model', 'fashion model', 'mannequin'], 'Q10843402': ['swimmer'], 'Q15981151': ['jazz musician'], 'Q82955': ['politician', 'political leader', 'polit.', 'political figure'], 'Q185351': ['jurist'], 'Q170790': ['mathematician'], 'Q1622272': ['university teacher', 'university teachers', 'lecturer', 'college lecturer', 'college professor'], 'Q2306091': ['sociologist'], 'Q36834': ['composer'], 'Q212980': ['psychologist'], 'Q16145150': ['music pedagogue', 'music teacher'], 'Q2516866': ['publisher'], 'Q13365117': ['handball player', 'handballer'], 'Q2309784': ['sport cyclist', 'racing cyclist', 'sport bicyclist', 'sport biker'], 'Q42973': ['architect'], 'Q3387717': ['theatre director', 'stage director', 'theater director'], 'Q10833314': ['tennis player'], 'Q593644': ['chemist', 'chemists']}\n"
     ]
    }
   ],
   "source": [
    "occupations_labels = {k: [v] for k, v in occupations_label.items()}\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT ?o ?altLabel \n",
    "WHERE {\n",
    "  VALUES ?o { %s }\n",
    "  ?o skos:altLabel ?altLabel . FILTER (lang(?altLabel) = \"en\")\n",
    "}\"\"\" % ' '.join('wd:' + o for o in occupations) \n",
    "\n",
    "for result in evalSparql(query):\n",
    "    occupations_labels[result['o']['value'].replace('http://www.wikidata.org/entity/', '')].append(result['altLabel']['value'])\n",
    "\n",
    "print(occupations_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia articles\n",
    "\n",
    "Here we load the training and the testing sets. To save memory space we use a generator that will read the file each time we iterate over the training or the testing examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "def loadJson(filename):\n",
    "    with gzip.open(filename, 'rt') as fp:\n",
    "        for line in fp:\n",
    "            yield json.loads(line)\n",
    "\n",
    "class MakeIter(object):\n",
    "    def __init__(self, generator_func, **kwargs):\n",
    "        self.generator_func = generator_func\n",
    "        self.kwargs = kwargs\n",
    "    def __iter__(self):\n",
    "        return self.generator_func(**self.kwargs)\n",
    "\n",
    "training_set = MakeIter(loadJson, filename='wiki-train.json.gz')\n",
    "testing_set = MakeIter(loadJson, filename='wiki-test.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract occupations from summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Dictionnary extraction\n",
    "\n",
    "> Using ```occupations_labels``` dictionnary, identify all occupations for each articles. Complete the function below to evaluate the accuracy of such approach. It will serve as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-82e54e11db51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnexample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mevaluate_dictionnary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moccupations_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-82e54e11db51>\u001b[0m in \u001b[0;36mevaluate_dictionnary\u001b[0;34m(training_set, occupations_labels)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0maccuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mnexample\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnexample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mevaluate_dictionnary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moccupations_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "def predict_dictionnary(example, occupations_labels):\n",
    "    ## example['summary'] contains the summary of the article\n",
    "    ## Code here\n",
    "    return None\n",
    "    \n",
    "def evaluate_dictionnary(training_set, occupations_labels):\n",
    "    nexample = 0\n",
    "    accuracy = 0.\n",
    "    prediction = None\n",
    "    for example in training_set:\n",
    "        prediction = predict_dictionnary(example, occupations_labels)\n",
    "        p = frozenset(prediction)\n",
    "        g = frozenset(example['occupations'])\n",
    "        accuracy += 1.*len(p & g) / len(p | g)\n",
    "        nexample += 1\n",
    "    return accuracy / nexample\n",
    "\n",
    "evaluate_dictionnary(training_set, occupations_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the articles \"summary\" and we take the average of the word vectors.\n",
    "This is done with spacy loaded with the fast text vectors.\n",
    "To do the installation/loading [takes 8-10 minutes, dl 1.2Go]\n",
    "```\n",
    "pip3 install spacy\n",
    "wget https://s3-us-west-1.amazonaws.com/fasttext-vectors/cc.en.300.vec.gz\n",
    "python3 -m spacy init-model en /tmp/en_vectors_wiki_lg --vectors-loc cc.en.300.vec.gz\n",
    "rm cc.en.300.vec.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model '/tmp/en_vectors_wiki_lg'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ab26cec09f25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/en_vectors_wiki_lg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exists'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model '/tmp/en_vectors_wiki_lg'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('/tmp/en_vectors_wiki_lg')\n",
    "\n",
    "def vectorize(dataset, nlp):\n",
    "    result = {}\n",
    "    for example in dataset:\n",
    "        doc = nlp(example['summary'], disable=['parser', 'tagger'])\n",
    "        result[example['title']] = {}\n",
    "        result[example['title']]['vector'] = doc.vector\n",
    "        if 'occupations' in example:\n",
    "            result[example['title']]['occupations'] = example['occupations']\n",
    "\n",
    "vectorized_training = vectorize(training_set, nlp)\n",
    "vectorized_testing = vectorize(testing_set, nlp)\n",
    "nlp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorized_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c8450fd3b56a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorized_training\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'George_Washington'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorized_training' is not defined"
     ]
    }
   ],
   "source": [
    "print(vectorized_training['George_Washington']['vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We encode the data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "inputs = np.array([vectorized_training[article]['vector'] for article in vectorized_training])\n",
    "outputs = np.array([[(1 if occupation in vectorized_training[article]['occupations'] else 0)\n",
    "                    for occupation in occupations ] for article in vectorized_training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-aa79e5399cb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using keras, define a sequential neural network with two layers. Use categorical_crossentropy as a loss function and softmax as the activation function of the output layer\n",
    "\n",
    "You can look into the documentation here: https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "## Compile the model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Then train the model on ```inputs``` and ```outputs```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Complete the function predict: output the list of occupations where the corresponding neuron on the output layer of our model has a value > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-6462291ffe24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Elvis_Presley'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorized_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# should be a subset of {'Q33999', 'Q177220', 'Q639669'}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def predict(model, article_name, vectorized_dataset):\n",
    "    prediction = None\n",
    "    ## Code here\n",
    "    return prediction\n",
    "\n",
    "print(predict(model, 'Elvis_Presley', vectorized_training))\n",
    "# should be {'Q177220'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nn(vectorized_training, model):\n",
    "    nexample = 0\n",
    "    accuracy = 0.\n",
    "    prediction = None\n",
    "    for article_name in vectorized_trainingset:\n",
    "        prediction = predict(model, article_name, vectorized_training)\n",
    "        p = frozenset(prediction)\n",
    "        g = frozenset(vectorized_training[article_name]['occupations'])\n",
    "        accuracy += 1.*len(p & g) / len(p | g)\n",
    "        nexample += 1\n",
    "    return accuracy / nexample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Your approach\n",
    "\n",
    "> Propose your own approach (extend previous examples or use original approaches) to improve the accuracy for this task. Apply it to the testing set and put the result as a json file with your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***IMPORTANT*** Output format of requested file 'results.json.gz': each line must be a json string representing a dictionnary:\n",
    "> ```{ 'title': THE_ARTICLE_NAME, 'prediction': [THE_LIST_OF_OCCUPATIONS]}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example if testset_solutions is a dictionnary: article_name (key) -> prediction_list (value) use this function:\n",
    "def export(testset_solutions):\n",
    "    with gzip.open('results.json.gz', 'wt') as output:\n",
    "        for article in testset_solutions:\n",
    "            output.write(json.dumps({'title':article, 'prediction':testset_solutions[article]}) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
